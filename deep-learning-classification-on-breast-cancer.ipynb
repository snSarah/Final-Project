{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/sitinursarah/deep-learning-classification-on-breast-cancer?scriptVersionId=144164596\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"# **Introduction**\n\nBreast cancer is a persistent issue all over the world. It can be detected in many ways through mammography, ultrasound, biopsy and so on. Detecting breast cancer early is vital as it increases the chance of a successful treatment, ultimately saving lives. Therefore, the development of an Image Classification Model for detecting Breast Cancer early is important. This notebook was implemented referring to previous works.\n\nThe aim for this project is:\n- To create an Image Classification Model that can accurately identify and categorize breast cancer cells from the non-cancerous images.\n\nThe objectives will be:\n- To use a suitable dataset on Breast Cancer images\n- Implement deep learning artchitectures such as Convolutional Neural Networks (CNN) to build the Image Classification Model.\n- Optimize the model with previously developed models and evaluate","metadata":{}},{"cell_type":"markdown","source":"# Data Collection\n\n## *Description of dataset used*\n\nBreast cancer can develop at any different part of the breast. The most common form of breast cancer is Invasive Ductal Carcinoma (IDC). In order to detect IDC, it is through various methods such as mammography, ultrasound, biopsy and so on. Through biopsy, histopathology images are derived.\n\nThe Dataset that is going to be used for training and testing for the image classification model will be the Breast Histopathology Images dataset.\n\nThe dataset was originally uploaded on the Gleason Case website: http://gleason.case.edu/webdata/jpi-dl-tutorial/IDC_regular_ps50_idx5.zip\n\nHowever, the website is not accessible as of now, thus we are using the dataset uploaded by Paul Mooney.\n\nIn this dataset, it consists a total of 277,524 patches of images sized 50 x 50, which was broken down from 162 whole mount images. Within these patches, there are 198, 738 IDC negative and 78,786 IDC positive. \n","metadata":{}},{"cell_type":"markdown","source":"## *Importing Necessary Modules*","metadata":{}},{"cell_type":"code","source":"# Basic Libraries\nimport numpy as np\nimport random\nfrom os import listdir\nfrom PIL import Image\n\n# Preprocessing/Visualization\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.utils import shuffle\nfrom keras.utils.np_utils import to_categorical\n\n# Model Creation\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\n\n# Evaluation Metrics\nimport seaborn as sns\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix","metadata":{"execution":{"iopub.status.busy":"2023-09-25T09:08:32.325952Z","iopub.execute_input":"2023-09-25T09:08:32.326336Z","iopub.status.idle":"2023-09-25T09:08:32.334456Z","shell.execute_reply.started":"2023-09-25T09:08:32.326303Z","shell.execute_reply":"2023-09-25T09:08:32.332533Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## *Importing Data*\n\nAfter carefully looking through the dataset, while the base path of the data is at breast-histopathology-images, there is a compilation of all the images into one folder which is named IDC_regular_ps50_idx5. For this project, the data from IDC_regular_ps50_idx5 folder will be directly extracted. It is a folder full of folders that is named after the patients' id, which also consists of the IDC positive and IDC negative photos. ","metadata":{}},{"cell_type":"code","source":"# Import the dataset into 'files'\n\nbase_path = \"../input/breast-histopathology-images/IDC_regular_ps50_idx5/\"\nfiles = listdir(base_path)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-09-25T09:08:32.35582Z","iopub.execute_input":"2023-09-25T09:08:32.356356Z","iopub.status.idle":"2023-09-25T09:08:32.383026Z","shell.execute_reply.started":"2023-09-25T09:08:32.356317Z","shell.execute_reply":"2023-09-25T09:08:32.382154Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Find the total length of data/Find out how many patients are there\n\nprint(\"Total Number of Patients: \"+ str(len(files)))","metadata":{"execution":{"iopub.status.busy":"2023-09-25T09:08:32.388485Z","iopub.execute_input":"2023-09-25T09:08:32.390092Z","iopub.status.idle":"2023-09-25T09:08:32.394637Z","shell.execute_reply.started":"2023-09-25T09:08:32.389996Z","shell.execute_reply":"2023-09-25T09:08:32.393729Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Based on what was printed above, it seems that there are 279 patients, and in each file contains images of IDC positive and negative. This information is useful as we are now aware on how to structure our files. Storing the data into the appropriate data structure is crucial as it will be easier to represent the data later. For this notebook, we will be using arrays to store the images and labels.","metadata":{}},{"cell_type":"code","source":"# Saving the data into an array [image_path, class]\n\ndataset = []\n\nfor i in range(len(files)):\n    patient_id = files[i]\n    for c in [0,1]:\n        patient_path = base_path + patient_id\n        class_path = patient_path + '/' + str(c) + '/'\n        subfiles = listdir(class_path)\n        for pic in subfiles:\n            image_path = class_path + pic\n            dataset.append([image_path,c])\n        ","metadata":{"execution":{"iopub.status.busy":"2023-09-25T09:08:32.417917Z","iopub.execute_input":"2023-09-25T09:08:32.419253Z","iopub.status.idle":"2023-09-25T09:08:33.827331Z","shell.execute_reply.started":"2023-09-25T09:08:32.419208Z","shell.execute_reply":"2023-09-25T09:08:33.825985Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Total Number of Images: \" + str(len(dataset)))","metadata":{"execution":{"iopub.status.busy":"2023-09-25T09:08:33.831573Z","iopub.execute_input":"2023-09-25T09:08:33.832913Z","iopub.status.idle":"2023-09-25T09:08:33.838151Z","shell.execute_reply.started":"2023-09-25T09:08:33.832838Z","shell.execute_reply":"2023-09-25T09:08:33.837052Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As shown above, there is a total of 277524 images. The way the images are stored is in two different arrays, where one is to store the images, the other is to store its type of class, IDC positive or negative, indicated with the numbers 0 and 1.","metadata":{}},{"cell_type":"code","source":"# How each data is stored\n\ndataset[0]","metadata":{"execution":{"iopub.status.busy":"2023-09-25T09:08:33.839669Z","iopub.execute_input":"2023-09-25T09:08:33.840577Z","iopub.status.idle":"2023-09-25T09:08:33.855938Z","shell.execute_reply.started":"2023-09-25T09:08:33.840546Z","shell.execute_reply":"2023-09-25T09:08:33.854634Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Each data in the dataset is formatted into a list type, which consists of the Image Path and its class 0 or 1, 0 being IDC negative and 1 being IDC postive.","metadata":{}},{"cell_type":"markdown","source":"The Dataset might be too big for my Kaggle notebook to run, so we will reduce it to a quarter. ","metadata":{}},{"cell_type":"code","source":"total_length = len(dataset)\nlimit = total_length/4\ndataset = dataset[:int(limit)]\n\nlen(dataset)","metadata":{"execution":{"iopub.status.busy":"2023-09-25T09:44:10.461083Z","iopub.execute_input":"2023-09-25T09:44:10.461519Z","iopub.status.idle":"2023-09-25T09:44:10.479122Z","shell.execute_reply.started":"2023-09-25T09:44:10.461487Z","shell.execute_reply":"2023-09-25T09:44:10.478077Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## *Data Visualisation*\n\nWhat does the image look like? And to what ratio is the IDC positive and IDC negative? This section will answer those questions.","metadata":{}},{"cell_type":"code","source":"# Get the size\n\n# Load the image\n\nimage_path = dataset[0][0]\nlabel = dataset[0][1]\nimage = Image.open(image_path)\n\n# Get the size (dimensions) of the image\n\nimage_width, image_height = image.size\n\nprint(f\"Image Width: {image_width} pixels\")\nprint(f\"Image Height: {image_height} pixels\")","metadata":{"execution":{"iopub.status.busy":"2023-09-25T09:08:33.883272Z","iopub.execute_input":"2023-09-25T09:08:33.883727Z","iopub.status.idle":"2023-09-25T09:08:33.913909Z","shell.execute_reply.started":"2023-09-25T09:08:33.883701Z","shell.execute_reply":"2023-09-25T09:08:33.912849Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"So each of these images are 50 by 50 pixels which was stated in the dataset itself. Here's what the first image looks like.","metadata":{}},{"cell_type":"code","source":"# Show the first image in the dataset\n\nplt.figure(figsize=(12, 8))\n\nplt.imshow(image)\nplt.title(\"IDC Negative\")\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-25T09:08:33.915151Z","iopub.execute_input":"2023-09-25T09:08:33.91546Z","iopub.status.idle":"2023-09-25T09:08:34.165117Z","shell.execute_reply.started":"2023-09-25T09:08:33.915432Z","shell.execute_reply":"2023-09-25T09:08:34.164002Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The dataset will be separated into NCdata and Cdata for the purpose of visualisation.","metadata":{}},{"cell_type":"code","source":"# Separate the data by class\n\nNCdata = [img for img, label in dataset if label == 0]\nCdata = [img for img, label in dataset if label == 1]\n\nNClabels = [label for img, label in dataset if label == 0]\nClabels = [label for img, label in dataset if label == 1]","metadata":{"execution":{"iopub.status.busy":"2023-09-25T09:08:34.166263Z","iopub.execute_input":"2023-09-25T09:08:34.167141Z","iopub.status.idle":"2023-09-25T09:08:34.213896Z","shell.execute_reply.started":"2023-09-25T09:08:34.167108Z","shell.execute_reply":"2023-09-25T09:08:34.211448Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"A sample of images will be taken from each data array for display.","metadata":{}},{"cell_type":"code","source":"# Get a sample of images from each type of dataset\n\nnegativeSample = random.sample(NCdata, 50)\npositiveSample = random.sample(Cdata, 50)","metadata":{"execution":{"iopub.status.busy":"2023-09-25T09:08:34.215453Z","iopub.execute_input":"2023-09-25T09:08:34.21595Z","iopub.status.idle":"2023-09-25T09:08:34.224178Z","shell.execute_reply.started":"2023-09-25T09:08:34.21591Z","shell.execute_reply":"2023-09-25T09:08:34.222439Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Healthy Patches","metadata":{}},{"cell_type":"code","source":"# Display 5x10 Grid of Healthy Patches\n\nfig, ax = plt.subplots(5,10,figsize=(20,10))\nfor n in range(5):\n    for m in range(10):\n        idx = negativeSample[m + 10*n]\n        image = Image.open(idx)\n        ax[n,m].imshow(image)\n        ax[n,m].grid(False)\n","metadata":{"execution":{"iopub.status.busy":"2023-09-25T09:08:34.22612Z","iopub.execute_input":"2023-09-25T09:08:34.226505Z","iopub.status.idle":"2023-09-25T09:08:40.532222Z","shell.execute_reply.started":"2023-09-25T09:08:34.226473Z","shell.execute_reply":"2023-09-25T09:08:40.531149Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Cancer Patches","metadata":{}},{"cell_type":"code","source":"# Display 5x10 Grid of Cancer Patches\n\nfig, ax = plt.subplots(5,10,figsize=(20,10))\nfor n in range(5):\n    for m in range(10):\n        idx = positiveSample[m + 10*n]\n        image = Image.open(idx)\n        ax[n,m].imshow(image)\n        ax[n,m].grid(False)","metadata":{"execution":{"iopub.status.busy":"2023-09-25T09:08:40.535603Z","iopub.execute_input":"2023-09-25T09:08:40.537041Z","iopub.status.idle":"2023-09-25T09:08:47.139932Z","shell.execute_reply.started":"2023-09-25T09:08:40.536988Z","shell.execute_reply":"2023-09-25T09:08:47.138819Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Observations:\n* There might be a chance that not all the images are 50x50pixels.\n* Comparing the Healthy Patches and the Cancer Patches, the Cancer patches seems to have more purpleish look to it.\n\n### Display Class Distribution","metadata":{}},{"cell_type":"code","source":"# Get the class distribution\n\nlabels = [\"Non-Cancer\", \"Cancer\"]\ncounts = [len(NCdata), len(Cdata)]\n\ntotal_samples = sum(counts)\npercentages = [(count / total_samples) * 100 for count in counts]\n","metadata":{"execution":{"iopub.status.busy":"2023-09-25T09:08:47.141937Z","iopub.execute_input":"2023-09-25T09:08:47.142491Z","iopub.status.idle":"2023-09-25T09:08:47.147944Z","shell.execute_reply.started":"2023-09-25T09:08:47.142465Z","shell.execute_reply":"2023-09-25T09:08:47.14649Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(8, 6))\nplt.bar(labels, counts)\nplt.xlabel(\"Class\")\nplt.ylabel(\"Count\")\nplt.title(\"Class Distribution\")\nplt.xticks(rotation=45)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-25T09:08:47.14961Z","iopub.execute_input":"2023-09-25T09:08:47.15057Z","iopub.status.idle":"2023-09-25T09:08:47.335708Z","shell.execute_reply.started":"2023-09-25T09:08:47.150535Z","shell.execute_reply":"2023-09-25T09:08:47.333881Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(8, 6))\nplt.pie(percentages, labels=labels, autopct='%1.1f%%', startangle=140)\nplt.title(\"Class Distribution (Percentage)\")\nplt.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-25T09:08:47.337887Z","iopub.execute_input":"2023-09-25T09:08:47.338242Z","iopub.status.idle":"2023-09-25T09:08:47.465774Z","shell.execute_reply.started":"2023-09-25T09:08:47.338211Z","shell.execute_reply":"2023-09-25T09:08:47.465016Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Preprocessing\n\nAs observed previously, not all images are 50x50 pixels. To avoid any issues during training, it is better to resize all images to follow the 50x50 size to ensure fairness. After resizing, normalization, shuffling and splitting the data will be carried out.","metadata":{}},{"cell_type":"code","source":"# Resizing using PIL Image\n\ndesired_size = (50,50)\nresizedNC = []\nresizedC = []\n\nfor image_path in NCdata:\n    image = Image.open(image_path)\n    nimage = image.resize(desired_size, Image.LANCZOS)  # Resize with anti-aliasing for better quality\n    resizedNC.append(nimage)\n    \nfor image_path in Cdata:\n    image = Image.open(image_path)\n    cimage = image.resize(desired_size, Image.LANCZOS)  # Resize with anti-aliasing for better quality\n    resizedC.append(cimage)\n","metadata":{"execution":{"iopub.status.busy":"2023-09-25T09:08:47.466843Z","iopub.execute_input":"2023-09-25T09:08:47.467427Z","iopub.status.idle":"2023-09-25T09:16:22.99125Z","shell.execute_reply.started":"2023-09-25T09:08:47.467398Z","shell.execute_reply":"2023-09-25T09:16:22.987997Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Normalize the Dataset pixel values to [0, 1] range\n\nNCdataset = np.array([np.array(image) / 255.0 for image in resizedNC])\nCdataset = np.array([np.array(image) / 255.0 for image in resizedC])","metadata":{"execution":{"iopub.status.busy":"2023-09-25T09:16:22.993692Z","iopub.status.idle":"2023-09-25T09:16:22.994542Z","shell.execute_reply.started":"2023-09-25T09:16:22.994163Z","shell.execute_reply":"2023-09-25T09:16:22.99422Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Shuffle the dataset\n\nNCdataset = shuffle(NCdataset, random_state=42)\nCdataset = shuffle(Cdataset, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2023-09-25T09:16:22.995748Z","iopub.status.idle":"2023-09-25T09:16:22.996207Z","shell.execute_reply.started":"2023-09-25T09:16:22.995998Z","shell.execute_reply":"2023-09-25T09:16:22.996015Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get the Shape of all dataset\n\nprint('NCdataset shape : {}' .format(NCdataset.shape))\nprint('Cdataset shape : {}' .format(Cdataset.shape))","metadata":{"execution":{"iopub.status.busy":"2023-09-25T09:16:22.997485Z","iopub.status.idle":"2023-09-25T09:16:22.997871Z","shell.execute_reply.started":"2023-09-25T09:16:22.997666Z","shell.execute_reply":"2023-09-25T09:16:22.997681Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Split the data\n\n# Split each dataset into training data and temporary data - 70:30\n\nNCtrain, NCtemp, NCtrain_labels, NCtemp_labels = train_test_split(\n    NCdataset, NClabels, test_size=0.3, stratify=NClabels, random_state=42\n)\n\n# Split the Cancer data\nCtrain, Ctemp, Ctrain_labels, Ctemp_labels = train_test_split(\n    Cdataset, Clabels, test_size=0.3, stratify=Clabels, random_state=42\n)\n\n# Use the temporary data to split into Validation and Testing Data - 15:15\nNCval, NCtest, NCval_labels, NCtest_labels = train_test_split(\n    NCtemp, NCtemp_labels, test_size=0.5, stratify=NCtemp_labels, random_state=42\n)\n\nCval, Ctest, Cval_labels, Ctest_labels = train_test_split(\n    Ctemp, Ctemp_labels, test_size=0.5, stratify=Ctemp_labels, random_state=42\n)\n\n# Combine the two Non-Cancer Data and the Cancer Data to make one train_data, val_data, test_data\ntrain_data = np.concatenate((NCtrain, Ctrain), axis=0)\ntrain_labels = np.concatenate((NCtrain_labels, Ctrain_labels), axis=0)\nval_data = np.concatenate((NCval, Cval), axis=0)\nval_labels = np.concatenate((NCval_labels, Cval_labels), axis=0)\ntest_data = np.concatenate((NCtest, Ctest), axis=0)\ntest_labels = np.concatenate((NCtest_labels, Ctest_labels), axis=0)","metadata":{"execution":{"iopub.status.busy":"2023-09-25T09:16:22.99895Z","iopub.status.idle":"2023-09-25T09:16:22.99927Z","shell.execute_reply.started":"2023-09-25T09:16:22.999119Z","shell.execute_reply":"2023-09-25T09:16:22.999134Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Reformat the shape for the labels\n\ntrain_labels = to_categorical(train_labels, 2)\nval_labels = to_categorical(val_labels, 2)\ntest_labels = to_categorical(test_labels, 2)","metadata":{"execution":{"iopub.status.busy":"2023-09-25T09:16:23.000687Z","iopub.status.idle":"2023-09-25T09:16:23.001048Z","shell.execute_reply.started":"2023-09-25T09:16:23.000883Z","shell.execute_reply":"2023-09-25T09:16:23.000901Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('train_data shape : {}' .format(train_data.shape))\nprint('train_labels shape : {}' .format(train_labels.shape))\nprint('val_data shape : {}' .format(val_data.shape))\nprint('val_labels shape : {}' .format(val_labels.shape))\nprint('test_data shape : {}' .format(test_data.shape))\nprint('test_labels shape : {}' .format(test_labels.shape))","metadata":{"execution":{"iopub.status.busy":"2023-09-25T09:16:23.002106Z","iopub.status.idle":"2023-09-25T09:16:23.002437Z","shell.execute_reply.started":"2023-09-25T09:16:23.002272Z","shell.execute_reply":"2023-09-25T09:16:23.002288Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model Architecture\n\nThe Model used for this project will be a custom Convolutional Neural Network model. Our base model consists of 11 layers.","metadata":{}},{"cell_type":"code","source":"model = tf.keras.Sequential([\n    # Convolutional Layers\n    tf.keras.layers.Conv2D(32, (3, 3), padding = 'same', activation = 'relu', input_shape = (50, 50, 3)),\n    tf.keras.layers.MaxPooling2D(strides = 2),\n    tf.keras.layers.Conv2D(64, (3, 3), padding = 'same', activation = 'relu'),\n    tf.keras.layers.MaxPooling2D((3, 3),strides = 2),\n    tf.keras.layers.Conv2D(128, (3, 3), padding = 'same', activation = 'relu'),\n    tf.keras.layers.MaxPooling2D((3, 3),strides =2),\n    tf.keras.layers.Conv2D(128, (3, 3), padding = 'same', activation = 'relu'),\n    tf.keras.layers.MaxPooling2D((3, 3),strides =2),\n    \n    # Flatten Layer\n    tf.keras.layers.Flatten(),\n    \n    # Fully Connected Layers\n    tf.keras.layers.Dense(128, activation = 'relu'),\n    tf.keras.layers.Dense(2, activation = 'softmax')\n])","metadata":{"execution":{"iopub.status.busy":"2023-09-25T09:16:23.003678Z","iopub.status.idle":"2023-09-25T09:16:23.004025Z","shell.execute_reply.started":"2023-09-25T09:16:23.003863Z","shell.execute_reply":"2023-09-25T09:16:23.003887Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2023-09-25T09:16:23.005153Z","iopub.status.idle":"2023-09-25T09:16:23.005463Z","shell.execute_reply.started":"2023-09-25T09:16:23.005315Z","shell.execute_reply":"2023-09-25T09:16:23.00533Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Hyperparameter Tuning\n\nThe Optimizer used for this model is Adam and the evaluation metrics is Accuracy.","metadata":{}},{"cell_type":"code","source":"model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),loss='binary_crossentropy',metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2023-09-25T09:16:23.006393Z","iopub.status.idle":"2023-09-25T09:16:23.0067Z","shell.execute_reply.started":"2023-09-25T09:16:23.006554Z","shell.execute_reply":"2023-09-25T09:16:23.006569Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model Training","metadata":{}},{"cell_type":"code","source":"history = model.fit(train_data, train_labels, validation_data = (val_data, val_labels), epochs = 25 , batch_size = 75)","metadata":{"execution":{"iopub.status.busy":"2023-09-25T09:16:23.007706Z","iopub.status.idle":"2023-09-25T09:16:23.008048Z","shell.execute_reply.started":"2023-09-25T09:16:23.007893Z","shell.execute_reply":"2023-09-25T09:16:23.007907Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model Evaluation","metadata":{}},{"cell_type":"code","source":"model.evaluate(test_data,test_labels)","metadata":{"execution":{"iopub.status.busy":"2023-09-25T09:16:23.009144Z","iopub.status.idle":"2023-09-25T09:16:23.009462Z","shell.execute_reply.started":"2023-09-25T09:16:23.009312Z","shell.execute_reply":"2023-09-25T09:16:23.009329Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('Model Accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-25T09:16:23.010227Z","iopub.status.idle":"2023-09-25T09:16:23.010536Z","shell.execute_reply.started":"2023-09-25T09:16:23.010386Z","shell.execute_reply":"2023-09-25T09:16:23.010401Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Model Loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-25T09:16:23.011444Z","iopub.status.idle":"2023-09-25T09:16:23.01178Z","shell.execute_reply.started":"2023-09-25T09:16:23.011606Z","shell.execute_reply":"2023-09-25T09:16:23.011622Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predict_data = model.predict(test_data)\npredict_labels = np.argmax(predict_data, axis=1)","metadata":{"execution":{"iopub.status.busy":"2023-09-25T09:16:23.012589Z","iopub.status.idle":"2023-09-25T09:16:23.012913Z","shell.execute_reply.started":"2023-09-25T09:16:23.012739Z","shell.execute_reply":"2023-09-25T09:16:23.012773Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def convert_to_single_label(one_hot_labels):\n    return np.argmax(one_hot_labels, axis=1)\n\n# Convert train_labels\ntrue_train_labels = convert_to_single_label(train_labels)\n\n# Convert val_labels\ntrue_val_labels = convert_to_single_label(val_labels)\n\n# Convert test_labels\ntrue_test_labels = convert_to_single_label(test_labels)","metadata":{"execution":{"iopub.status.busy":"2023-09-25T09:16:23.014262Z","iopub.status.idle":"2023-09-25T09:16:23.014599Z","shell.execute_reply.started":"2023-09-25T09:16:23.014444Z","shell.execute_reply":"2023-09-25T09:16:23.01446Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n\n\n# Calculate accuracy\naccuracy = accuracy_score(true_test_labels, predict_labels)\nprint(f'Accuracy: {accuracy:.2f}')\n\n# Calculate precision\nprecision = precision_score(true_test_labels, predict_labels)\nprint(f'Precision: {precision:.2f}')\n\n# Calculate recall\nrecall = recall_score(true_test_labels, predict_labels)\nprint(f'Recall: {recall:.2f}')\n\n# Calculate F1-score\nf1 = f1_score(true_test_labels, predict_labels)\nprint(f'F1-score: {f1:.2f}')\n\n# Calculate confusion matrix\nconf_matrix = confusion_matrix(true_test_labels, predict_labels)\nf,ax = plt.subplots(figsize=(8, 8))\nsns.heatmap(conf_matrix, annot=True, linewidths=0.01,cmap=\"BuPu\",linecolor=\"gray\", fmt= '.1f',ax=ax)\nplt.xlabel(\"Predicted Label\")\nplt.ylabel(\"True Label\")\nplt.title(\"Confusion Matrix\")\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-09-25T09:16:23.015435Z","iopub.status.idle":"2023-09-25T09:16:23.015788Z","shell.execute_reply.started":"2023-09-25T09:16:23.015607Z","shell.execute_reply":"2023-09-25T09:16:23.015623Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Fine Tuning\n\nA new model is created after evaluating from the previous one. For the model, more layers were added, and is using Early Stopping.\n","metadata":{}},{"cell_type":"code","source":"model2 = keras.Sequential([\n    # Convolutional Layers\n    layers.Conv2D(32, (3, 3), padding='same', activation='relu', input_shape=(50, 50, 3)),\n    layers.MaxPooling2D(strides=2),\n    layers.Conv2D(64, (3, 3), padding='same', activation='relu'),\n    layers.MaxPooling2D((3, 3), strides=2),\n    layers.Conv2D(128, (3, 3), padding='same', activation='relu'),\n    layers.MaxPooling2D((3, 3), strides=2),\n    layers.Conv2D(256, (3, 3), padding='same', activation='relu'),\n    layers.MaxPooling2D((3, 3), strides=2),\n    \n    # Flatten Layer\n    layers.Flatten(),\n    \n    # Fully Connected Layers\n    layers.Dense(256, activation='relu'),\n    layers.Dense(128, activation='relu'),\n    layers.Dense(2, activation='softmax')\n])","metadata":{"execution":{"iopub.status.busy":"2023-09-25T09:16:23.01652Z","iopub.status.idle":"2023-09-25T09:16:23.016847Z","shell.execute_reply.started":"2023-09-25T09:16:23.016668Z","shell.execute_reply":"2023-09-25T09:16:23.016682Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model2.summary()","metadata":{"execution":{"iopub.status.busy":"2023-09-25T09:16:23.018386Z","iopub.status.idle":"2023-09-25T09:16:23.01868Z","shell.execute_reply.started":"2023-09-25T09:16:23.018538Z","shell.execute_reply":"2023-09-25T09:16:23.018552Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model2.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001),loss='binary_crossentropy',metrics=['accuracy'])\n","metadata":{"execution":{"iopub.status.busy":"2023-09-25T09:16:23.019426Z","iopub.status.idle":"2023-09-25T09:16:23.019718Z","shell.execute_reply.started":"2023-09-25T09:16:23.019573Z","shell.execute_reply":"2023-09-25T09:16:23.019588Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"early_stopping = keras.callbacks.EarlyStopping(\n    monitor='val_loss',  # Metric to monitor (e.g., validation loss)\n    patience=5,           # Number of epochs with no improvement to wait before stopping\n    restore_best_weights=True  # Restore model weights to the best epoch\n)","metadata":{"execution":{"iopub.status.busy":"2023-09-25T09:16:23.02098Z","iopub.status.idle":"2023-09-25T09:16:23.021304Z","shell.execute_reply.started":"2023-09-25T09:16:23.021135Z","shell.execute_reply":"2023-09-25T09:16:23.021153Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history2 = model2.fit(train_data, train_labels, validation_data = (val_data, val_labels), epochs = 25 , batch_size = 256, callbacks=[early_stopping])","metadata":{"execution":{"iopub.status.busy":"2023-09-25T09:16:23.022869Z","iopub.status.idle":"2023-09-25T09:16:23.023182Z","shell.execute_reply.started":"2023-09-25T09:16:23.023033Z","shell.execute_reply":"2023-09-25T09:16:23.023048Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model2.evaluate(test_data,test_labels)","metadata":{"execution":{"iopub.status.busy":"2023-09-25T09:16:23.024268Z","iopub.status.idle":"2023-09-25T09:16:23.024565Z","shell.execute_reply.started":"2023-09-25T09:16:23.024421Z","shell.execute_reply":"2023-09-25T09:16:23.024436Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(history2.history['accuracy'])\nplt.plot(history2.history['val_accuracy'])\nplt.title('Model Accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-25T09:16:23.025627Z","iopub.status.idle":"2023-09-25T09:16:23.025947Z","shell.execute_reply.started":"2023-09-25T09:16:23.025799Z","shell.execute_reply":"2023-09-25T09:16:23.025814Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(history2.history['loss'])\nplt.plot(history2.history['val_loss'])\nplt.title('Model Loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-25T09:16:23.027029Z","iopub.status.idle":"2023-09-25T09:16:23.027323Z","shell.execute_reply.started":"2023-09-25T09:16:23.02718Z","shell.execute_reply":"2023-09-25T09:16:23.027195Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predict_data = model2.predict(test_data)\npredict_labels = np.argmax(predict_data, axis=1)","metadata":{"execution":{"iopub.status.busy":"2023-09-25T09:16:23.028159Z","iopub.status.idle":"2023-09-25T09:16:23.02847Z","shell.execute_reply.started":"2023-09-25T09:16:23.028306Z","shell.execute_reply":"2023-09-25T09:16:23.02832Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n\n\n# Calculate accuracy\naccuracy = accuracy_score(true_test_labels, predict_labels)\nprint(f'Accuracy: {accuracy:.2f}')\n\n# Calculate precision\nprecision = precision_score(true_test_labels, predict_labels)\nprint(f'Precision: {precision:.2f}')\n\n# Calculate recall\nrecall = recall_score(true_test_labels, predict_labels)\nprint(f'Recall: {recall:.2f}')\n\n# Calculate F1-score\nf1 = f1_score(true_test_labels, predict_labels)\nprint(f'F1-score: {f1:.2f}')\n\n# Calculate confusion matrix\nconf_matrix = confusion_matrix(true_test_labels, predict_labels)\nf,ax = plt.subplots(figsize=(8, 8))\nsns.heatmap(conf_matrix, annot=True, linewidths=0.01,cmap=\"BuPu\",linecolor=\"gray\", fmt= '.1f',ax=ax)\nplt.xlabel(\"Predicted Label\")\nplt.ylabel(\"True Label\")\nplt.title(\"Confusion Matrix\")\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-09-25T09:16:23.029597Z","iopub.status.idle":"2023-09-25T09:16:23.029976Z","shell.execute_reply.started":"2023-09-25T09:16:23.029799Z","shell.execute_reply":"2023-09-25T09:16:23.029821Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Analysis\n\nJust based on the accuracy score between the two models created, it is proven that the second level gives a better accuracy score. \n","metadata":{}},{"cell_type":"markdown","source":"# Discussion\n\nInterpret the results obtained from the image classification model\n\nAnalyze the implications of the findings in the context of the research questions or objectives\n\nAddress any limitations or constraints of the model and potential areas for improvement \n","metadata":{}},{"cell_type":"markdown","source":"# Conclusion\n\nSummarize the key findings and contributions of the image classification model\n\nDiscuss the implications of the results for the broader field of image classification and its potential applications\n","metadata":{}}]}